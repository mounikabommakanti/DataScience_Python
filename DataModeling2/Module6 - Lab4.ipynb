{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module6- Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intentionally missing! Read the directions on the course lab page!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this lab, you'll get started with decision trees by revisiting UCI's wheat-seeds dataset, so you can benchmark how long it takes to train and predict with decision trees relative to the speed of KNeighbors and SVC, as well as compare the decision boundary plots produced by it.\n",
    "\n",
    "No starter code this time. Instead, take your completed Module6/Module6 - Lab1.ipynb and modify it by adding in a Decision Tree Classifier, setting its max_depth to 9, and random_state=2, but not altering any other setting.\n",
    "Make sure you add in the benchmark and drawPlots call for our new classifier as well.\n",
    "Answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "C = 1\n",
    "kernel = 'linear'\n",
    "iterations = 5000\n",
    "FAST_DRAW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawPlots(model, X_train, X_test, y_train, y_test, wintitle='Figure 1'):\n",
    "    # You can use this to break any higher-dimensional space down,\n",
    "    # And view cross sections of it.\n",
    "\n",
    "    # If this line throws an error, use plt.style.use('ggplot') instead\n",
    "    mpl.style.use('ggplot') # Look Pretty\n",
    "\n",
    "    padding = 3\n",
    "    resolution = 0.5\n",
    "    max_2d_score = 0\n",
    "\n",
    "    y_colors = ['#ff0000', '#00ff00', '#0000ff']\n",
    "    my_cmap  = mpl.colors.ListedColormap(['#ffaaaa', '#aaffaa', '#aaaaff'])\n",
    "    colors   = [y_colors[i] for i in y_train]\n",
    "    num_columns = len(X_train.columns)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.canvas.set_window_title(wintitle)\n",
    "    fig.set_tight_layout(True)\n",
    "    \n",
    "    cnt = 0\n",
    "    for col in range(num_columns):\n",
    "        for row in range(num_columns):\n",
    "            \n",
    "            # Easy out\n",
    "            if FAST_DRAW and col > row:\n",
    "                cnt += 1\n",
    "                continue\n",
    "\n",
    "            ax = plt.subplot(num_columns, num_columns, cnt + 1)\n",
    "            plt.xticks(())\n",
    "            plt.yticks(())\n",
    "\n",
    "            # Intersection:\n",
    "            if col == row:\n",
    "                plt.text(0.5, 0.5, X_train.columns[row], verticalalignment='center', horizontalalignment='center', fontsize=12)\n",
    "                cnt += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Only select two features to display, then train the model\n",
    "            X_train_bag = X_train.ix[:, [row,col]]\n",
    "            X_test_bag = X_test.ix[:, [row,col]]\n",
    "            model.fit(X_train_bag, y_train)\n",
    "\n",
    "            # Create a mesh to plot in\n",
    "            x_min, x_max = X_train_bag.ix[:, 0].min() - padding, X_train_bag.ix[:, 0].max() + padding\n",
    "            y_min, y_max = X_train_bag.ix[:, 1].min() - padding, X_train_bag.ix[:, 1].max() + padding\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                                 np.arange(y_min, y_max, resolution))\n",
    "\n",
    "            # Plot Boundaries\n",
    "            plt.xlim(xx.min(), xx.max())\n",
    "            plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "            # Prepare the contour\n",
    "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            plt.contourf(xx, yy, Z, cmap=my_cmap, alpha=0.8)\n",
    "            plt.scatter(X_train_bag.ix[:, 0], X_train_bag.ix[:, 1], c=colors, alpha=0.5)\n",
    "\n",
    "\n",
    "            score = round(model.score(X_test_bag, y_test) * 100, 3)\n",
    "            plt.text(0.5, 0, \"Score: {0}\".format(score), transform = ax.transAxes, horizontalalignment='center', fontsize=8)\n",
    "            max_2d_score = score if score > max_2d_score else max_2d_score\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "    print(\"Max 2D Score: \", max_2d_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(model, X_train, X_test, y_train, y_test, wintitle='Figure 1'):\n",
    "    print(wintitle + ' Results')\n",
    "    s = time.time()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # TODO: train the classifier on the training data / labels:\n",
    "        \n",
    "        # .. your code here ..\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "    print(\"{0} Iterations Training Time: \".format(iterations), time.time() - s)\n",
    "\n",
    "\n",
    "    s = time.time()\n",
    "    for i in range(iterations):\n",
    "        # TODO: score the classifier on the testing data / labels:\n",
    "\n",
    "        # .. your code here ..\n",
    "        score=model.score(X_test,y_test)\n",
    "        \n",
    "    print(\"{0} Iterations Scoring Time: \".format(iterations), time.time() - s)\n",
    "    print(\"High-Dimensionality Score: \", round((score*100), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Results\n",
      "('5000 Iterations Training Time: ', 2.6389999389648438)\n",
      "('5000 Iterations Scoring Time: ', 1.5339999198913574)\n",
      "('High-Dimensionality Score: ', 68.852)\n",
      "('Max 2D Score: ', 68.852)\n",
      "KNeighbors Results\n",
      "('5000 Iterations Training Time: ', 2.4850001335144043)\n",
      "('5000 Iterations Scoring Time: ', 5.310999870300293)\n",
      "('High-Dimensionality Score: ', 83.607)\n",
      "('Max 2D Score: ', 90.164)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "X=pd.read_csv('Datasets/wheat.data')\n",
    "X=X.drop(labels=['id'],axis=1)\n",
    "X.dropna(axis=0,inplace=True)\n",
    "y=X[['wheat_type']]\n",
    "X.drop('wheat_type',axis=1,inplace=True)\n",
    "#X.drop('asymmetry',axis=1,inplace=True)\n",
    "y=y['wheat_type'].map({'canadian':0,'kama':1,'rosa':2})\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.30, random_state=7)\n",
    "\n",
    "model = tree.DecisionTreeClassifier(max_depth=1,random_state=2)\n",
    "#, criterion=\"entropy\")\n",
    "\n",
    "#svc= SVC(kernel='linear',C=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "benchmark(model, X_train, X_test, y_train, y_test, 'DecisionTree')\n",
    "drawPlots(model, X_train, X_test, y_train, y_test, 'DecisionTree')\n",
    "\n",
    "benchmark(knn, X_train, X_test, y_train, y_test, 'KNeighbors')\n",
    "drawPlots(knn, X_train, X_test, y_train, y_test, 'KNeighbors')\n",
    "\n",
    "#benchmark(svc, X_train, X_test, y_train, y_test, 'SVC')\n",
    "#drawPlots(svc, X_train, X_test, y_train, y_test, 'SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure everyone is on the same page, irrespective of the parameters you had on Module6 - Lab1.ipynb, go ahead and make the following changes:\n",
    "\n",
    "C = 1  \n",
    "kernel = 'linear'  \n",
    "iterations = 5000  \n",
    "n_neighbors = 5  \n",
    "max_depth = 9\n",
    "\n",
    "Which of the following statements is true?\n",
    "a.DTrees beat SVC's score in the original, high-D feature space; but SVC has the highest 2D score\n",
    "b.KNeighbors has the highest 2D score; but no one beats SVC's score in the original, high-D feature space\n",
    "c. KNeighbors and DTrees both tie in their scoring of accuracy in the original, high-D feature space\n",
    "d. DTrees are the worst in the original, high-D feature space; but have the best max 2D score\n",
    "correct:a\n",
    "\n",
    "\n",
    "Lab Question 2\n",
    "1/1 point (graded)\n",
    "Keep dropping the max_depth of the decision tree down until it's high-dimensionality score is less than KNeighbors, and then stop.\n",
    "\n",
    "What is the max_depth value that you hit?\n",
    "correct:max_depth=one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
